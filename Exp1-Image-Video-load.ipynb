{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3051dff",
   "metadata": {},
   "source": [
    "### *Ralngam**\n",
    "M.Tech AI 3rd Semester\n",
    "\n",
    "NIELIT-IMPHAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78527fa8",
   "metadata": {},
   "source": [
    "# Experiment 1: Image /Video Reading and Display\n",
    "Develop a Python program using OpenCV to demonstrate image acquisition and video acquisition\n",
    "by reading images in multiple modes and capturing live video from a camera, displaying and storing\n",
    "the video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc225459",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow\n",
    "from IPython.display import display, Javascript, HTML\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "\n",
    "\n",
    "# IMAGE ACQUISITION\n",
    "\n",
    "print(\"IMAGE\")\n",
    "# Download image\n",
    "!wget -q -O input_sample.jpg https://raw.githubusercontent.com/opencv/opencv/master/samples/data/butterfly.jpg\n",
    "\n",
    "# Read in different modes\n",
    "img_color = cv2.imread('input_sample.jpg', cv2.IMREAD_COLOR)      # BGR\n",
    "img_gray = cv2.imread('input_sample.jpg', cv2.IMREAD_GRAYSCALE)  # Grayscale\n",
    "img_unchanged = cv2.imread('input_sample.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "print(\"Color Image:\")\n",
    "cv2_imshow(img_color)\n",
    "\n",
    "print(\"Grayscale Image:\")\n",
    "cv2_imshow(img_gray)\n",
    "\n",
    "\n",
    "\n",
    "# VIDEO ACQUISITION\n",
    "\n",
    "print(\"\\n WebCam VIDEO \")\n",
    "\n",
    "def record_video_js(seconds=5):\n",
    "    js = Javascript('''\n",
    "        async function recordVideo(seconds) {\n",
    "            const div = document.createElement('div');\n",
    "            const video = document.createElement('video');\n",
    "            video.style.display = 'block';\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "            document.body.appendChild(div);\n",
    "            div.appendChild(video);\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "\n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            const ctx = canvas.getContext('2d');\n",
    "            \n",
    "            const frames = [];\n",
    "            const endTime = Date.now() + (seconds * 1000);\n",
    "\n",
    "            while (Date.now() < endTime) {\n",
    "                ctx.drawImage(video, 0, 0);\n",
    "                frames.push(canvas.toDataURL('image/jpeg', 0.5));\n",
    "                await new Promise(r => setTimeout(r, 100)); // ~10 fps\n",
    "            }\n",
    "\n",
    "            stream.getVideoTracks()[0].stop();\n",
    "            div.remove();\n",
    "            return frames;\n",
    "        }\n",
    "    ''')\n",
    "    display(js)\n",
    "    return eval_js(f'recordVideo({seconds})')\n",
    "\n",
    "try:\n",
    "    # Capture frames\n",
    "    raw_frames = record_video_js(seconds=5)\n",
    "    \n",
    "    # VideoWriters Setup\n",
    "    first_frame_bytes = b64decode(raw_frames[0].split(',')[1])\n",
    "    first_frame = cv2.imdecode(np.frombuffer(first_frame_bytes, np.uint8), -1)\n",
    "    h, w, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    out_rgb = cv2.VideoWriter('output_rgb.avi', fourcc, 10.0, (w, h))\n",
    "    out_gray = cv2.VideoWriter('output_gray.avi', fourcc, 10.0, (w, h), isColor=False)\n",
    "\n",
    "    # Process and Save Frames\n",
    "    for frame_data in raw_frames:\n",
    "        img_bytes = b64decode(frame_data.split(',')[1])\n",
    "        frame_bgr = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Grayscale Conversion\n",
    "        frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        out_rgb.write(frame_bgr)\n",
    "        out_gray.write(frame_gray)\n",
    "\n",
    "    out_rgb.release()\n",
    "    out_gray.release()\n",
    "    print(\"Video recording complete.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# DISPLAY\n",
    "\n",
    "print(\"\\n DISPLAY\")\n",
    "\n",
    "# Convert to MP4 for browser\n",
    "!ffmpeg -i output_rgb.avi -vcodec libx264 -f mp4 rgb_final.mp4 -y -loglevel quiet\n",
    "!ffmpeg -i output_gray.avi -vcodec libx264 -f mp4 gray_final.mp4 -y -loglevel quiet\n",
    "\n",
    "def show_video(file_name):\n",
    "    mp4 = open(file_name,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return HTML(f'<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')\n",
    "\n",
    "print(\"RGB Video:\")\n",
    "display(show_video('rgb_final.mp4'))\n",
    "\n",
    "print(\"Grayscale Video:\")\n",
    "display(show_video('gray_final.mp4'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
